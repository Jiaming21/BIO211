cat("Summary statistics for cars with 4 cylinders:\n")
cat("Mean:", mean_4_cyl, "\n")
cat("Standard Deviation:", std_dev_4_cyl, "\n")
cat("\nSummary statistics for cars with 6 cylinders:\n")
cat("Mean:", mean_6_cyl, "\n")
cat("Standard Deviation:", std_dev_6_cyl, "\n")
cat("\nSummary statistics for cars with 8 cylinders:\n")
cat("Mean:", mean_8_cyl, "\n")
cat("Standard Deviation:", std_dev_8_cyl, "\n")
# Create a boxplot to visualize the distribution of mpg for each group
boxplot(mpg ~ cyl, data = mtcars, main = "MPG Distribution by Cylinder Count", xlab = "Cylinders", ylab = "Miles Per Gallon")
# Are there any noticeable differences in the mpg distribution among cars with different cylinder counts?
# You can visually inspect the boxplot to identify differences in the distribution of mpg for different cylinder counts.
# Insert your code here
# Load the mtcars dataset
data(mtcars)
# Set two random values in the hp variable to NA
set.seed(123)  # Setting a seed for reproducibility
missing_indices <- sample(1:length(mtcars$hp), 2)
mtcars$hp[missing_indices] <- NA
# Calculate the mean and median of the hp variable with missing data
mean_hp_with_missing <- mean(mtcars$hp, na.rm = TRUE)
median_hp_with_missing <- median(mtcars$hp, na.rm = TRUE)
cat("Mean horsepower (with missing values):", mean_hp_with_missing, "\n")
cat("Median horsepower (with missing values):", median_hp_with_missing, "\n")
# Create a new dataset without missing values in the hp variable
mtcars_no_missing_hp <- mtcars[!is.na(mtcars$hp), ]
# Plot a boxplot for the hp variable in the original dataset
boxplot(mtcars$hp, main = "Horsepower Distribution (Original)", xlab = "Original Dataset")
# Plot a boxplot for the hp variable in the modified dataset (without missing values)
boxplot(mtcars_no_missing_hp$hp, main = "Horsepower Distribution (No Missing Values)", xlab = "Modified Dataset")
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 || data >= 80 - 15] # Yes, follow Empirical Rule
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 || data >= 80 - 15] # Yes, follow Empirical Rule
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 || data >= 80 - 15] # Yes, follow Empirical Rule
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 || data >= 80 - 15] # Yes, follow Empirical Rule
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 || data >= 80 - 15] # Yes, follow Empirical Rule
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 || data >= 80 - 15] # Yes, follow Empirical Rule
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 || data >= 80 - 15] # Yes, follow Empirical Rule
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 || data >= 80 - 15] # Yes, follow Empirical Rule
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 || data >= 80 - 15] # Yes, follow Empirical Rule
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 || data >= 80 - 15] # Yes, follow Empirical Rule
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 || data >= 80 - 15] # Yes, follow Empirical Rule
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 & data >= 80 - 15] # Yes, follow Empirical Rule
data_2d <- data[data <= 80 + 2*15 || data >= 80 - 2*15]
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 & data >= 80 - 15] # Yes, follow Empirical Rule
data_2d <- data[data <= 80 + 2*15 & data >= 80 - 2*15]
data_3d <- data[data <= 80 + 3*15 || data >= 80 - 3*15]
# Insert your code here
data <- rnorm(1000, mean = 80, sd = 15)
data_1d <- data[data <= 80 + 15 & data >= 80 - 15] # Yes, follow Empirical Rule
data_2d <- data[data <= 80 + 2*15 & data >= 80 - 2*15]
data_3d <- data[data <= 80 + 3*15 & data >= 80 - 3*15]
data_1d <- student_scores[student_scores <= (mean_score + std_deviation) & student_scores >= (mean_score - std_deviation)]
# Insert your code here
# data <- rnorm(1000, mean = 80, sd = 15)
#
# data_1d <- data[data <= 80 + 15 & data >= 80 - 15] # Yes, follow Empirical # Rule
# data_2d <- data[data <= 80 + 2*15 & data >= 80 - 2*15]
# data_3d <- data[data <= 80 + 3*15 & data >= 80 - 3*15]
#
# data_1d <- student_scores[student_scores <= (mean_score + std_deviation) & # student_scores >= (mean_score - std_deviation)]
# Set the random seed for reproducibility
set.seed(123)
# Generate 1000 student scores following a normal distribution
mean_score <- 80
std_deviation <- 15
num_scores <- 1000
student_scores <- rnorm(num_scores, mean_score, std_deviation)
# Calculate the percentage of scores within one standard deviation of the mean
within_one_std_dev <- sum(student_scores >= (mean_score - std_deviation) & student_scores <= (mean_score + std_deviation)) / num_scores * 100
# Calculate the percentage of scores within two standard deviations of the mean
within_two_std_dev <- sum(student_scores >= (mean_score - 2 * std_deviation) & student_scores <= (mean_score + 2 * std_deviation)) / num_scores * 100
# Calculate the percentage of scores within three standard deviations of the mean
within_three_std_dev <- sum(student_scores >= (mean_score - 3 * std_deviation) & student_scores <= (mean_score + 3 * std_deviation)) / num_scores * 100
cat("Percentage of scores within one standard deviation of the mean:", within_one_std_dev, "%\n")
cat("Percentage of scores within two standard deviations of the mean:", within_two_std_dev, "%\n")
cat("Percentage of scores within three standard deviations of the mean:", within_three_std_dev, "%\n")
# Load the mtcars dataset
data(mtcars)
# Calculate the mean and median of the mpg variable
mean_mpg <- mean(mtcars$mpg)
median_mpg <- median(mtcars$mpg)
cat("Mean MPG:", mean_mpg, "\n")
cat("Median MPG:", median_mpg, "\n")
# Calculate the standard deviation and variance of the hp variable
std_dev_hp <- sd(mtcars$hp)
variance_hp <- var(mtcars$hp)
cat("Standard Deviation of HP:", std_dev_hp, "\n")
cat("Variance of HP:", variance_hp, "\n")
# Calculate the range of the wt variable
range_wt <- range(mtcars$wt)
cat("Range of WT (Weight):", range_wt[1], "to", range_wt[2], "\n")
# Create a histogram for the mpg variable
hist(mtcars$mpg, main = "MPG Distribution", xlab = "Miles Per Gallon (mpg)", ylab = "Frequency")
# Analysis of the histogram:
# The histogram provides a visual representation of the distribution of mpg in the dataset.
# You can observe the shape and central tendency of the data. In this case, you can see whether the data is normally distributed or if there are any clear patterns or outliers.
# Load the dataset or create a sample dataset with a normal distribution
# For this example, let's create a sample dataset
set.seed(123)  # Set a seed for reproducibility
scores <- rnorm(1000, mean = 80, sd = 15)
# Calculate the mean and standard deviation of the dataset
mean_score <- mean(scores)
sd_score <- sd(scores)
# Calculate the percentage of scores that fall within one standard deviation of the mean
# According to the Empirical Rule, approximately 68% of the scores fall within one standard deviation of the mean.
within_one_sd <- sum(scores >= (mean_score - sd_score) & scores <= (mean_score + sd_score)) / length(scores) * 100
# Display the result
cat("Approximately", round(within_one_sd, 2), "% of scores fall within one standard deviation of the mean.")
# Load the mtcars dataset
data(mtcars)
# a) Calculate the mean and median of mpg
mean_mpg <- mean(mtcars$mpg)
median_mpg <- median(mtcars$mpg)
# b) Calculate the standard deviation and variance of hp
sd_hp <- sd(mtcars$hp)
var_hp <- var(mtcars$hp)
# c) Find the range of wt
range_wt <- range(mtcars$wt)
# d) Create a histogram for mpg
hist(mtcars$mpg, main="Histogram of MPG", xlab="Miles per Gallon (mpg)", col="lightblue")
# Load the mtcars dataset
data(mtcars)
# a) Set two random values in hp to NA
set.seed(123)
mtcars$hp[sample(1:32, 2)] <- NA
# b) Calculate the mean and median of hp with missing data
mean_hp <- mean(mtcars$hp, na.rm = TRUE)
median_hp <- median(mtcars$hp, na.rm = TRUE)
# c) Create a new dataset without missing values in hp
mtcars_clean <- na.omit(mtcars)
# d) Create boxplots for hp in both datasets
par(mfrow=c(1,2))
boxplot(mtcars$hp, main="Boxplot of hp (Original)", col="lightblue")
boxplot(mtcars_clean$hp, main="Boxplot of hp (Cleaned)", col="lightgreen")
# Read data
path <- '/Users/jiaming/Desktop/BIO211_pre/Datas'
setwd(paste(path))
rm(list = ls())
# Read data
path <- '/Users/jiaming/Desktop/BIO211_pre/Datas'
setwd(paste(path))
rm(list = ls())
protein <- read.csv('PvD_combine.csv', header = T, sep = ',', stringsAsFactors = F,
quote = "", row.names = 1)
protein
LFQ <- protein[, -1]
LFQ
2^LFQ
LFQ
P_D
P_D <- 2^LFQ
P_D
# DEP analysis
pvalue <- apply(P_D[, c(1:30)], 1, function(x) {
a <- factor(c(rep("Distal", 15), rep("Proximal", 15)))
t.test(x~a, var.equal = T, alternative = "two.sided", conf.level = 0.95)
})
result_t.test <- data.frame(gene_symbol=protein$Gene.Name,
Pvalue = as.numeric(unlist(lapply(pvalue, function(x) x$p.value))),
log2FC = log2(as.numeric(unlist(lapply(pvalue,
function(x) x$estimate[1]/x$estimate[2]))))
)
rownames(result_t.test) <- rownames(protein)
t.test_fdr <- p.adjust(result_t.test$Pvalue, method = 'fdr')
result_t.test_fdr <- cbind(result_t.test, t.test_fdr)
dep <- result_t.test_fdr[result_t.test_fdr$t.test_fdr < 0.05 & abs(result_t.test_fdr$log2FC) > 1, ]
dep1 <- dep[order(abs(dep$log2FC), decreasing=T),]
write.table(dep1, file = 'dep_fdr_raw.txt', sep = '\t',quote = F, row.names = F)
library(cowplot)
library(patchwork)
library(ggplotify)
library(ggplot2)
library(ggrepel)
logFC_cutoff <- 1
result_t.test_fdr <- result_t.test_fdr[which (result_t.test_fdr$gene_symbol != ""), ]
anno <- read.csv('volcano_anno.csv', header = T, sep = ',', stringsAsFactors = F,
quote = "", row.names = 1)
result_t.test_fdr$change = as.factor(
ifelse (result_t.test_fdr$t.test_fdr < 0.05 & abs(result_t.test_fdr$log2FC) > logFC_cutoff,
ifelse (result_t.test_fdr$log2FC > logFC_cutoff,"UP","DOWN"),"NOT")
)
result_t.test_fdr$change = as.factor(
ifelse (result_t.test_fdr$t.test_fdr < 0.05 & abs(result_t.test_fdr$log2FC) > logFC_cutoff,
ifelse (result_t.test_fdr$log2FC > logFC_cutoff,"UP","DOWN"),"NOT")
)
up_down <- table(result_t.test_fdr$change)
loc_up <- which(result_t.test_fdr$change == 'UP')
loc_down <- which(result_t.test_fdr$change == 'DOWN')
significant <- rep('normal', times=nrow(result_t.test_fdr))
significant[loc_up] <- 'up'
significant[loc_down] <- 'down'
significant <- factor(significant, levels = c('up', 'down', 'normal'))
result_t.test_fdr_new = cbind(result_t.test_fdr, anno)
p <- qplot(x = result_t.test_fdr_new$log2FC,
y = -log10(result_t.test_fdr_new$t.test_fdr),
xlab = 'log2(FC)', ylab = '-log10(FDR)',
size=I(2), alpha = I(1/3), colour=significant)
p <- p+scale_color_manual(values = c('up'='red', 'normal' = 'gray', 'down'='blue'))
# Add cutoff line
xline = c(-logFC_cutoff,logFC_cutoff)
p <- p+geom_vline(xintercept = xline, lty = 2, size = I(0.2), color = 'grey11')
yline = -log(0.05,10)
p <- p+geom_hline(yintercept = yline, lty = 2, size = I(0.2), color = 'grey11')
# Label gene names of interest
p <- p+geom_text_repel(aes(label = result_t.test_fdr_new$label),
point.padding = unit(0.25, "lines"),
arrow = arrow(length = unit(0.01, "npc")),
nudge_y = 0.1)
p <- p+theme_bw() + theme(panel.background = element_rect(colour = 'black',
size = 1, fill = 'white'),
panel.grid = element_blank(),
axis.title.x = element_text(size = 15) ,
axis.title.y = element_text(size = 15),
axis.text.x = element_text(size = 15),
axis.text.y = element_text(size = 15),
legend.title = element_text(size = 12),
legend.text = element_text(size = 10))
ggsave('volcano_dep.pdf')
# Set work path, read data and data statistics
path<-'/Users/jiaming/Desktop/BIO211/Lab 4/gene_expression_data_analysis/datas'
setwd(paste(path))
# Set work path, read data and data statistics
path<-'/Users/jiaming/Desktop/BIO211_pre/Lab 4/gene_expression_data_analysis/datas'
setwd(paste(path))
# Set work path, read data and data statistics
path<-'/Users/jiaming/Desktop/BIO211_pre/Lab4/gene_expression_data_analysis/datas'
setwd(paste(path))
rm(list=ls())
a=read.csv('LIHC_counts_lab4.csv')
a=read.csv('LIHC_counts_lab4.csv')
a
DEG2$change=as.factor(+ ifelse(DEG2$PValue<0.05 & abs(DEG2$logFC) > logFC_cutoff2, ifelse(DEG2$logFC > logFC_cutoff2,"UP","DOWN"),"NOT")+ )
# Select significant genes exhibiting differential expression
## Method 1: edgeR
library(edgeR)
dge<-DGEList(counts=a, group=group_list)
design<-model.matrix(~0+group_list)
rownames(design)<-colnames(dge)
colnames(design)<-levels(group_list)
dge<-estimateGLMCommonDisp(dge,design)
dge<-estimateGLMTrendedDisp(dge,design)
dge<-estimateGLMTagwiseDisp(dge,design)
# Set work path, read data and data statistics
path<-'/Users/jiaming/Desktop/BIO211_pre/Lab4/gene_expression_data_analysis/datas'
setwd(paste(path))
rm(list=ls()) # 清空env
a=read.csv('LIHC_counts_lab4.csv')
dim(a)
row.names(a)<-a[,1]
a<-a[,-1]
group_list<-ifelse(as.numeric(substr(colnames(a),14,15))<10,'tumor','normal')
# Separate samples into two groups
# Check the hints on TCGA Barcode for how to differentiate tumor/normal samples
group_list<-factor(group_list,levels=c("normal","tumor"))
table(group_list)
View(a)
# Select significant genes exhibiting differential expression
## Method 1: edgeR
library(edgeR)
dge<-DGEList(counts=a, group=group_list)
dge$samples$lib.size<-colSums(dge$counts)
design<-model.matrix(~0+group_list)
rownames(design)<-colnames(dge)
colnames(design)<-levels(group_list)
dge<-estimateGLMCommonDisp(dge,design)
dge<-estimateGLMTrendedDisp(dge,design)
dge<-estimateGLMTagwiseDisp(dge,design)
fit<-glmFit(dge,design)
fit2<-glmLRT(fit,contrast=c(-1,1))
DEG2=topTags(fit2, n=nrow(a))
table(DEG2$change)
## Method 2: limma-voom
library(limma)
design<-model.matrix(~0+group_list)
colnames(design)=levels(group_list)
rownames(design)=colnames(a)
dge<-DGEList(counts=a)
dge<-calcNormFactors(dge)
logCPM<-cpm(dge,log=TRUE,prior.count=3)
v<-voom(dge,design,normalize="quantile")
fit<-lmFit(v,design)
constra=paste(rev(levels(group_list)),collapse="-")
cont.matrix<-makeContrasts(contrasts=constra,levels=design)
fit3=contrasts.fit(fit,cont.matrix)
fit3=eBayes(fit3)
DEG3=topTable(fit3,coef=constra,n=Inf)
DEG3=na.omit(DEG3)
logFC_cutoff3<-with(DEG3,mean(abs(logFC)+2*sd(abs(logFC))))
DEG3$change=as.factor(
ifelse(DEG3$P.Value<0.05 & abs(DEG3$logFC) > logFC_cutoff3,
ifelse(DEG3$logFC > logFC_cutoff3,"UP","DOWN"),"NOT")
)
head(DEG3)
table(DEG3$change)
## Save your results
edgeR_DEG<-DEG2
limma_voom_DEG<-DEG3
save(edgeR_DEG,limma_voom_DEG,group_list,file='DEG.Rdata')
##################   Data Visualization by Volcano Plot   ######################
# Data preparation
library(stringr)
rownames(DEG2)<-str_sub(rownames(DEG2),start=1,end=15)
DEG2$ENSEMBL<-rownames(DEG2)
diff_gene<-DEG2[DEG2$change!='NOT',]
write.table(diff_gene,
file=path,
sep='\t',quote=F)
# Construct a volcano plot
# install.packages('ggplot2')
library(cowplot)
library(patchwork)
library(ggplotify)
library(ggplot2)
loc_up<-intersect(which(DEG2$FDR<0.05),which(DEG2$logFC>=1))
loc_down<-intersect(which(DEG2$FDR<0.05),which(DEG2$logFC<(-1)))
significant<-rep('normal',times=nrow(DEG2))
significant[loc_up]<-'up'
significant[loc_down]<-'down'
significant<-factor(significant,levels=c('up','down','normal'))
p<-qplot(x=DEG2$logFC,y=-log10(DEG2$FDR),xlab='log2(FC)',ylab='-log10(FDR)',         + size=I(0.7),colour=significant)
p<-p+scale_color_manual(values=c('up'='red','normal'='grey','down'='blue'))
## Add cut-off lines & export image
xline=c(-log2(2),log2(2))
p<-p+geom_vline(xintercept = xline,lty=2,size=I(0.2),color='grey11')
yline=-log(0.05,10)
p<-p+geom_hline(yintercept = yline,lty=2,size=I(0.2),color='grey11')
p<-p+theme_bw()+theme(panel.background = element_rect(colour = 'black',                                                      + size=1,fill='white'),panel.grid=element_blank())
pdf('deg2_volcano.pdf')
print(p)
dev.off()
################  Set work path, read data and data statistics   ###############
path <- '/Users/jiaming/Desktop/BIO211_pre/Lab4_re/gene/datas'
setwd(path)
rm(list=ls())
a=read.csv('LIHC_counts_lab4.csv')
dim(a) # 60488 425 ｜ 行是每个基因表达量，列是样本名（是否是normal还是tumor样本）
row.names(a) <- a[,1] # 选出第一列作为行名
a <- a[,-1] # 去除第一列
group_list <- ifelse(as.numeric(substr(colnames(a),14,15)) < 10,'tumor','normal')
group_list <- factor(group_list, levels=c("normal","tumor"))
table(group_list)
View(a) # Check the data matrix
## Method 1: edgeR
library(edgeR)
dge<-DGEList(counts=a, group=group_list)
# 查看DGEList的属性
attributes(dge)
attributes(dge$samples)
dge$samples$lib.size<-colSums(dge$counts) # 为samples加上列的总计数信息
# dge$samples$lib.size有425个数，对应425个样本
design<-model.matrix(~0+group_list) # 425行，两列分别对应normal与tumor
# 相当于就是给每组是tumor还是normal做编码
# 创建没有截距的设计矩阵
# 其中每一列对应于样本分组（group_list）的水平。
# 这个设计矩阵将用于线性模型，以描述基因表达在不同分组之间的变化。
# 在差异表达分析中，通过比较不同分组的系数，可以识别基因的差异表达。
rownames(design)<-colnames(dge) # 将TCGA编号给矩阵的行名
colnames(design)<-levels(group_list) # 将factor的"normal"和"tumor"给design的列名
dge<-estimateGLMCommonDisp(dge,design) # 估算基因表达数据的离散度（dispersion）
dge<-estimateGLMTrendedDisp(dge,design) # 估算每个基因的趋势离散度（trended dispersion）
dge<-estimateGLMTagwiseDisp(dge,design) # 估算基因表达数据的标记依赖离散度（tagwise dispersion）
fit<-glmFit(dge,design) # 拟合一个广义线性模型（GLM）到基因表达数据
fit2<-glmLRT(fit,contrast=c(-1,1)) # 进行广义线性模型（GLM）的似然比检验（Likelihood Ratio Test，LRT）
# contrast=c(-1,1) 设置是指定似然比检验中的对比（contrast）系数
DEG2=topTags(fit2, n=nrow(a))
# fit2 是先前通过 glmLRT 进行似然比检验得到的结果对象，其中包含了每个基因的统计信息。
# topTags 是 edgeR 包中的函数，用于提取在检验中具有最高统计显著性的基因。
# nrow(a) 给定了你想要提取的基因的数量，通常是数据集中所有的基因的数量。
# 这里使用 nrow(a) 是为了提取所有的基因。
DEG2=as.data.frame(DEG2) # 只用logFC属性
# 结果对象 DEG2 包含了似然比检验中具有最高统计显著性的基因的信息，
# 包括基因的名称
# 对应的 p-value
# 调整过的 p-value（如果进行了多重检验校正的话）
# 估计的对数折算比（logFC）
logFC_cutoff2<-with(DEG2, mean(abs(logFC))+2*sd(abs(logFC)))
# 计算一个对数折算比（logFC）的阈值
# 用于确定哪些基因在似然比检验中被认为是显著差异表达的
DEG2$change=as.factor(
ifelse(DEG2$PValue<0.05 & abs(DEG2$logFC)>logFC_cutoff2,
ifelse(DEG2$logFC>logFC_cutoff2,"UP","DOWN"),"NOT")
)
# 为 DEG2 数据框添加一个名为 change 的列，该列用于表示每个基因的差异表达情况
head(DEG2)
## Method 2: limma-voom
library(limma)
design<-model.matrix(~0+group_list) # 搞一个基准为0的矩阵，对tumor还是normal进行编码，一共425个样本（是normal/tumor）
colnames(design)=levels(group_list) # 列名注释为normal还是tumor
rownames(design)=colnames(a) # 给矩阵的行以样本名
dge<-DGEList(counts=a) # 创建一个DGEList给dge
dge<-calcNormFactors(dge)
# 计算规范化因子（normalization factors）的函数
# 在差异表达分析中，规范化是为了消除不同样本之间的技术偏差和批次效应，
# 以便更准确地比较基因表达水平
logCPM<-cpm(dge,log=TRUE,prior.count=3) # 计算每百万对数
# log counts per million，logCPM
# dge 是一个 DGEList 对象，包含原始的基因计数数据以及实验设计和样本信息
# cpm 是 edgeR 包中的函数，用于计算每百万对数计数。
# log = TRUE 参数指定返回的值是对数变换后的，即 logCPM
# prior.count = 3 参数指定加入一个小的平滑值，以避免在计算对数时遇到零值
# 这是为了稳定对数变换，尤其是在计算对数时避免零计数导致无穷大或负无穷大的问题
v<-voom(dge,design,normalize="quantile")
# 使用 voom 函数进行基因表达数据的转换，将数据转换为适用于线性模型的形式
fit<-lmFit(v,design)
# 使用 lmFit 函数对 voom 转换后的数据进行线性模型的拟合
constra=paste(rev(levels(group_list)),collapse="-")
cont.matrix<-makeContrasts(contrasts=constra,levels=design)
# 创建一个对比矩阵（contrast matrix）用于在 limma 包中进行线性模型的分析
fit3=contrasts.fit(fit,cont.matrix)
# fit3 是包含了应用对比矩阵后的线性模型的结果对象，用于进行后续的统计分析
fit3=eBayes(fit3) # 对已经应用了对比矩阵的线性模型进行贝叶斯估计
DEG3=topTable(fit3,coef=constra,n=Inf) # 从贝叶斯估计后的线性模型结果中提取差异表达基因（DEG）
DEG3=na.omit(DEG3) # 使用 na.omit 函数去除结果对象 DEG3 中包含缺失值（NA，Not Available）的行
logFC_cutoff3<-with(DEG3,mean(abs(logFC)+2*sd(abs(logFC))))
DEG3$change=as.factor(
ifelse(DEG3$P.Value<0.05 & abs(DEG3$logFC) > logFC_cutoff3,
ifelse(DEG3$logFC > logFC_cutoff3,"UP","DOWN"),"NOT")
)
head(DEG3)
# Count the number of up- and down-regulated genes
table(DEG3$change)
# Save your results
edgeR_DEG<-DEG2
limma_voom_DEG<-DEG3
save(edgeR_DEG,limma_voom_DEG,group_list,file='DEG.Rdata')
# 1. Data preparation
library(stringr)
rownames(DEG2)<-str_sub(rownames(DEG2),start=1,end=15)
DEG2$ENSEMBL<-rownames(DEG2)
diff_gene<-DEG2[DEG2$change!='NOT',]
write.table(diff_gene,
file=paste0(path,'/LIHC_diff_gene.txt'),
sep='\t',
quote=F)
################  Set work path, read data and data statistics   ###############
path <- '/Users/jiaming/Desktop/BIO211_pre/Lab4_re/gene/datas'
diff_gene<-DEG2[DEG2$change!='NOT',]
write.table(diff_gene,
file=paste0(path,'/LIHC_diff_gene.txt'),
sep='\t',
quote=F)
# 2.  Construct a volcano plot
# install.packages('ggplot2')
library(cowplot)
library(patchwork)
library(ggplotify)
library(ggplot2)
loc_up<-intersect(which(DEG2$FDR<0.05),which(DEG2$logFC>=1))
loc_down<-intersect(which(DEG2$FDR<0.05),which(DEG2$logFC<(-1)))
significant<-rep('normal',times=nrow(DEG2))
significant[loc_up]<-'up'
significant[loc_down]<-'down'
significant<-factor(significant,levels=c('up','down','normal'))
p<-qplot(x=DEG2$logFC,
y=-log10(DEG2$FDR),
xlab='log2(FC)',
ylab='-log10(FDR)',
size=I(0.7),colour=significant)
p<-p+scale_color_manual(values=c('up'='red','normal'='grey','down'='blue'))
## Add cut-off lines & export image
xline=c(-log2(2),log2(2))
p<-p+geom_vline(xintercept = xline,lty=2,size=I(0.2),color='grey11')
yline=-log(0.05,10)
p<-p+geom_hline(yintercept = yline,lty=2,size=I(0.2),color='grey11')
p<-p+theme_bw()+theme(panel.background = element_rect(colour = 'black',size=1,fill='white'),panel.grid=element_blank())
pdf('deg2_volcano.pdf')
print(p)
dev.off()
# install.packages('pheatmap')
cg1=rownames(edgeR_DEG)[edgeR_DEG$change!='NOT']
cg2=rownames(limma_voom_DEG)[limma_voom_DEG$change!='NOT']
library(pheatmap)
library(RColorBrewer)
color<-colorRampPalette(c('#436EEE','white','#EE0000'))(100)
## Hierarchical clustering on edgeR produced significant genes
mat1=a[cg1,]
n1=t(scale(t(mat1)))
n1[n1>1]=1
n1[n1<-1]=-1
ac=data.frame(group=group_list)
rownames(ac)=colnames(mat1)
ht1<-pheatmap(n1,show_rownames = F,show_colnames = F,
cluster_rows = F,cluster_cols = T,
annotation_col = ac, color = color)
print(ht1)
